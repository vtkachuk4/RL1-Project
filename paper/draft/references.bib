@article{pan2019fuzzy,
  title   = {Fuzzy tiling activations: A simple approach to learning sparse representations online},
  author  = {Pan, Yangchen and Banman, Kirby and White, Martha},
  journal = {arXiv preprint arXiv:1911.08068},
  year    = {2019}
}

@article{mnih2013playing,
  title   = {Playing atari with deep reinforcement learning},
  author  = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal = {arXiv preprint arXiv:1312.5602},
  year    = {2013}
}

@article{silver2017mastering,
  title     = {Mastering the game of go without human knowledge},
  author    = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal   = {nature},
  volume    = {550},
  number    = {7676},
  pages     = {354--359},
  year      = {2017},
  publisher = {Nature Publishing Group}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}

@inproceedings{bullinaria1995,
  title={Representation , Learning , Generalization and Damage in Neural Network Models of Reading Aloud},
  author={John A. Bullinaria},
  year={1995}
}

@article{iCaRL2016,
  author    = {Sylvestre{-}Alvise Rebuffi and
               Alexander Kolesnikov and
               Christoph H. Lampert},
  title     = {iCaRL: Incremental Classifier and Representation Learning},
  journal   = {CoRR},
  volume    = {abs/1611.07725},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.07725},
  eprinttype = {arXiv},
  eprint    = {1611.07725},
  timestamp = {Fri, 20 Nov 2020 14:04:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/RebuffiKL16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{le2017,
  author    = {Lei Le and Raksha Kumaraswamy and Martha White},
  title     = {Learning Sparse Representations in Reinforcement Learning with Sparse Coding},
  booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on
               Artificial Intelligence, {IJCAI-17}},
  pages     = {2067--2073},
  year      = {2017},
  doi       = {10.24963/ijcai.2017/287},
  url       = {https://doi.org/10.24963/ijcai.2017/287}
}

@article{liu2019,
  author    = {Vincent Liu and
               Raksha Kumaraswamy and
               Lei Le and
               Martha White},
  title     = {The Utility of Sparse Representations for Control in Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1811.06626},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.06626},
  eprinttype = {arXiv},
  eprint    = {1811.06626},
  timestamp = {Sun, 25 Nov 2018 18:57:12 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1811-06626.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{liu2020,
  author    = {Vincent Liu and
               Adam White and
               Hengshuai Yao and
               Martha White},
  title     = {Towards a practical measure of interference for reinforcement learning},
  journal   = {CoRR},
  volume    = {abs/2007.03807},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.03807},
  eprinttype = {arXiv},
  eprint    = {2007.03807},
  timestamp = {Thu, 21 Apr 2022 11:57:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2007-03807.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{bengio2020,
  title = 	 {Interference and Generalization in Temporal Difference Learning},
  author =       {Bengio, Emmanuel and Pineau, Joelle and Precup, Doina},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {767--777},
  year = 	 {2020},
  editor = 	 {III, Hal Daum√© and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/bengio20a/bengio20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/bengio20a.html},
  abstract = 	 {We study the link between generalization and interference in temporal-difference (TD) learning. Interference is defined as the inner product of two different gradients, representing their alignment; this quantity emerges as being of interest from a variety of observations about neural networks, parameter sharing and the dynamics of learning. We find that TD easily leads to low-interference, under-generalizing parameters, while the effect seems reversed in supervised learning. We hypothesize that the cause can be traced back to the interplay between the dynamics of interference and bootstrapping. This is supported empirically by several observations: the negative relationship between the generalization gap and interference in TD, the negative effect of bootstrapping on interference and the local coherence of targets, and the contrast between the propagation rate of information in TD(0) versus TD($\lambda$) and regression tasks such as Monte-Carlo policy evaluation. We hope that these new findings can guide the future discovery of better bootstrapping methods.}
}

@ARTICLE{zhang2022,
  author={Zhang, Tiantian and Wang, Xueqian and Liang, Bin and Yuan, Bo},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Catastrophic Interference in Reinforcement Learning: A Solution Based on Context Division and Knowledge Distillation}, 
  year={2022},
  volume={},
  number={},
  pages={1-15},
  doi={10.1109/TNNLS.2022.3162241}
}
@article{ghiassian2020,
  author    = {Sina Ghiassian and
               Banafsheh Rafiee and
               Yat Long Lo and
               Adam White},
  title     = {Improving Performance in Reinforcement Learning by Breaking Generalization
               in Neural Networks},
  journal   = {CoRR},
  volume    = {abs/2003.07417},
  year      = {2020},
  url       = {https://arxiv.org/abs/2003.07417},
  eprinttype = {arXiv},
  eprint    = {2003.07417},
  timestamp = {Mon, 25 Apr 2022 11:12:20 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2003-07417.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{javed2019,
  author    = {Khurram Javed and
               Martha White},
  title     = {Meta-Learning Representations for Continual Learning},
  journal   = {CoRR},
  volume    = {abs/1905.12588},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.12588},
  eprinttype = {arXiv},
  eprint    = {1905.12588},
  timestamp = {Mon, 03 Jun 2019 13:42:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-12588.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{sutton2019,
  title={Learning Sparse Representations Incrementally in Deep Reinforcement Learning},
  author={J. Fernando Hernandez-Garcia and Richard S. Sutton},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.04002}
}

@InProceedings{tilecoding,
author="Sherstov, Alexander A.
and Stone, Peter",
editor="Zucker, Jean-Daniel
and Saitta, Lorenza",
title="Function Approximation via Tile Coding: Automating Parameter Choice",
booktitle="Abstraction, Reformulation and Approximation",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="194--205",
abstract="Reinforcement learning (RL) is a powerful abstraction of sequential decision making that has an established theoretical foundation and has proven effective in a variety of small, simulated domains. The success of RL on real-world problems with large, often continuous state and action spaces hinges on effective function approximation. Of the many function approximation schemes proposed, tile coding strikes an empirically successful balance among representational power, computational cost, and ease of use and has been widely adopted in recent RL work. This paper demonstrates that the performance of tile coding is quite sensitive to parameterization. We present detailed experiments that isolate the effects of parameter choices and provide guidance to their setting. We further illustrate that no single parameterization achieves the best performance throughout the learning curve, and contribute an automated technique for adjusting tile-coding parameters online. Our experimental findings confirm the superiority of adaptive parameterization to fixed settings. This work aims to automate the choice of approximation scheme not only on a problem basis but also throughout the learning process, eliminating the need for a substantial tuning effort.",
isbn="978-3-540-31882-8"
}

@article{ddpg,
author = {Lillicrap, Timothy and Hunt, Jonathan and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
year = {2015},
month = {09},
pages = {},
title = {Continuous control with deep reinforcement learning},
journal = {CoRR}
}

@misc{nnrep,
  doi = {10.48550/ARXIV.2203.15955},
  url = {https://arxiv.org/abs/2203.15955},
  author = {Wang, Han and Miahi, Erfan and White, Martha and Machado, Marlos C. and Abbas, Zaheer and Kumaraswamy, Raksha and Liu, Vincent and White, Adam},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Investigating the Properties of Neural Network Representations in Reinforcement Learning},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}